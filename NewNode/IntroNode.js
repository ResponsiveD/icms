Node 3 Building blocks
libuv -> a high performance, cross-platform evented io library.
V8 -> Google's JS engine
js,C++ -> 

one of the key concept of the node is event loop, el constantly listening on the dom event such as key process or mouse clicks similarly node event loops constantly listening the event loop server side,

timers, tcp, httpl events generated by node events aditionally other events can be res togethered comes to the external resources ex.
1. asking node profile for reading 
2. file or file event open to ready sending message to a process 
3. firing the event when the msg has been send
4. making a req sending resources such as another web server 
5. fire an event http res recieve 

key points each of the event has node, infact a event very likely extream each other for example in this diagram bw req for file when the file is reading and both tcp and http event recv while  send msg to process and wait any of the req complete, simply react the event to arrive

generated query from the database some info, once node rec event back to the db complete http res formulated send to the col, all of these rec res from db forever, its not block its free to handle, 2 req still waiting for first one to compl 
 this non blocking approuch is fundamental to node diff more traditional serv side progr modal require to manage multiple follows to achieve these type of cuncurrency

// In this case return almore immediately, before the actual work as been done we have to find convey the other, if u get the connectDB, it takes two paras 
1. same conn before 
2. is a function 
Get a conn to the database all, while craptin the base node keep to other work to the database to establish.

writing a code a non block asyu env 

a typical approach

var con = getDbConnection(connectionString);
var stmt = con.createStatement();
var results = stmt.executeQuery(sqlQuery);
for(var i=0;i<results.length;i++){
	// print results[i];
}

an async 'non-blocking' approach

getDbConnection(connectionString, function(err, conn){// callback
	// these function set call once the statment as been created
	// these 2 func ex of callbacks node will run async, node is exe function ideed the value, in these obj return from the function doesn't imm contains result of the db query 
	// however the let do return function disappear 
	conn.createStatement(function(err, stmt){ // callback
		var result = stmt.executeQuery(sqlQuery);
		results.on('row', function(result){ // eventemitter
			// print results
			// its the special obj called eventemitter which capable of meeting event in the future which each query becomes available, here telling a node point whole event emitted whole objs 
		})
	})
});


// Node abopted concuptions 
getStuff(inputParam, handleResults)
// the node handle parameter always last param passed to the async function here the callback is a named function
// and onther conversion use of callback error handling 
var handleResults = function(error, results) {
	// if error is undefined
	// do something with the results
}
// for simple callbacks, async function are more common, only return once 

getStuff(inputParam, function(error, results){
	// if error
});

// a simple callback only used once in a apprach, anonymous used in the colon function, handle gist stuff to the anonymous function, another benefit for anonymous function with js support clousures, use can access all var the variable along the way 

var maxTime = 1000;

// If input is even, double it
// If input is odd, error
// (call takes random amount of time < 1s)

var evenDouble = function  (v, callback) {
	var waitTime = Math.floor(Math.random()*(maxTime+1))
	if (v%2) {
		setTimeout(function  () {
			callback(new Error("Odd input"));
		}, waitTime);
	}else {
		setTimeout(function  () {
			callback(null, v*2, waitTime);
		})
	}
}

var handleResults = function  (err, results, time) {
	if (err) {
		console.log("Error: ", err.message)
	} else {
		console.log("The result are: "+ results +" ("+time+" ms");
	}
}

// evenDouble(2, handleResults);
// evenDouble(3, handleResults);
// evenDouble(10, handleResults);
// // even 2
// // even 10
// // odd 3

var count = 0;

for (var i = 0; i<10; i++) {
	console.log("Calling evenDouble for value: "+i);
	evenDouble(i, function  (err, results, time) {
		if (err) {
			console.log("Error: ", err.message)
		} else {
			console.log("The result are: "+ results +" ("+time+" ms");
		}
		if (++count === 10) {console.log("Done!")};
	})
};


console.log("--------------------");

module, require() and NPM

var foo = require('foo');
explictly export an use of application, a module can export specific var and these vars can also be function some times a module can export in your object simply expand ur code


3 sources of Node modules
1. Builtin modules/ included ur project to be used
Are require()'d a simple id
A simple of buil9n modules include
	fs, http, crypto, os

var os = require('os');

var toMb = function  (f) {
	return(Math.round((f/1024/1024)*100)/100)
}

console.log("Host: "+os.hostname());
console.log("15 mins, load avarage: "+os.loadavg()[2]);
console.log(toMb(os.freemem())+ ' of ' +toMb(os.totalmem()) + ' Mb free');


2. Your Project's files

Each .js file is its own module
great way to modularize ur apps code make it easier to deve and maintain
Each file is require()'d' with file system-like sematics
single variable require() still valid:
var justOne = require('./data').justOne;

variable are marked for export via 'module.exports'

3. Third Party Modules via NPM registry
Installed via "npm install module_name" into "node_modules" folder
Are require()'d' via string id, similar to built-ins
	-- Node understand folder structure to load the appropriate js code 
Can require() individual files from within a module, but be careful
	-- similar to loading a single function require 
	var BlobResult = require('azure/lib/service/blob/models/blobresult');
// while technically feasible extream care, falling the single file and deep with the single module function may introduce the level of coupling may authoring model

Event and eventemitter class
Non-blocking doesn't always mean callbacks
getThem(param, function(err, items){ //callbacks
	// check for error
	// operate on array of items
})
// --Request/Reply
// In the callback function particular func has been called. One req/replay
// --No results until all results
// In the callback approach u don't receive any results until all results.
// The callback will not be invoke until all items are ready if these items arrive slowly will not to be invoke until last items arrive, it also means get them function storing entire list itm in mem accumulating them priority invoking the array
// --Either errors or results
// its only by convention all are nothing proposition where technically possible the callback invoke erro and items params, this is not the convention it might not expected, the error parameter accept the calls assume to fails 


var results = getThem(param);

results.on('item', function(){ // events
	// do something with this one item
	// the value instance of the eventEmitter class, this result obj has on function in this function each event items exe them current event items
})
results.on('done', function(){ // events
})
results.on('error', function(){ // events
})
// --PUB/SUB
// the event model PUB/SUB approach, to invite on func repeatedly to provide multi provide function on invoke on each event and subscribing to the evnet
// --Act on result as they arrive
// In the other hand func assoc with the item event invoke for the each itm, its give me opportunity act as an 1 items arrive and soon
// it also get them function not accumulating in the mem
// --Partial results before error
// don't pass the error event as the first value, error can be any item events already item emitted, this access to partial result of some situation 

Node"EventEmitter" class,
Provided by node contract building event node pharses 
Sub
emitter.on(event, listener);
Pub
emitter.emit(event, [args]);

. The "event" can be any string 
. An event can be emitted with zero or more args
.. provide addtional args, these are passed to params any func subs to the events 
. The set of events and their args constitute a "interface" exposed to the subscriber by the publisher (emitter).

Two common patterns for EE:
1. As a return value from a function call
2. Objects that extend EE to emit events themselves


var EventEmitter = require('events').EventEmitter;

var getResource = function  (c) {
	var e = new EventEmitter();
	// process nexttick is similar to settimeout, event list is nextTick on this function, and this ex emulate async func coz we want return value before emitting event 
	process.nextTick(function  () {
		var count = 0;
		e.emit('start');
		var t = setInterval(function  () {
			e.emit('data', ++count);
			if(count === c){
				e.emit('end', count);
				clearInterval(t);
			}
		}, 10)
	});
	return(e);
}

var r = getResource(5);

// SUB part
r.on('start', function  () {
	console.log('I"ve started')
})

r.on('data', function  (d) {
	console.log('I receive data ->'+d)
})

r.on('end', function  (t) {
	console.log('I m done with '+t+' data events.')
})

var util = require('util')
var EventEmitter = require('events').EventEmitter;

function Resource   (c) {
	var maxEvents = c;
	var self = this;
	// from resource function inherits from event emitter, resource function leading the event 
	process.nextTick(function  () {
		var count = 0;
		self.emit('start');
		var t = setInterval(function  () {
			self.emit('data', ++count);
			if(count === c){
				self.emit('end', count);
				clearInterval(t);
			}
		}, 10)
	});
}
// our obj extends from inherit parameter, which gives us access to the on and emit function
util.inherits(Resource, EventEmitter);

var r = new Resource(5);

// SUB part
r.on('start', function  () {
	console.log('I"ve started')
})

r.on('data', function  (d) {
	console.log('I receive data ->'+d)
})

r.on('end', function  (t) {
	console.log('I m done with '+t+' data events.')
})

Readable and Writable Streams the Pipe function

Stream are instances of (and extensions to) eventEmitter with an agreed upon "interface"
A unified abstraction for managing multiple type of data flow, including
	. Network traffic (http req and res, tcp sockets)
	. File IO
	. stdin/stdout/sterr
	. and more 
A stream is an instace of either
	. ReadableStream
	. WritableStream
	. .... or both
A ReadStream can be pipe() to WriteableStream
	. Applies 'backpressure'

coz of standard function expose readable and writable stream, similar to linux RS can expose faster pipe to WS can backpressure

RS
- readable[boolean]/ incating the read or not
- event: 'data', 'end', 'error', 'close' - serieous event emitter arrives new more data
- pause(), resume(), destroy(), pipe() function,

WS
- writable[boolean]/ incating the write or not
- event: 'drain', 'error', 'close', 'pipe'
- wite(), end(), destroy(), destroySoon()

// are us cretainly interact with stream directly, sub to events invoke function directly, the real power of streams come from the pipe function, let see how to gethered how to pipe functionality
// when invoke the function pipe as readable stream will pass as a pipe function writablestream, this interm read event in the writable stream,

// the data arrived readablestream emitted and invoke the function writable, if the some points write function return false value, to indicate the pasuse() function stop indicating data, then writable stream receive more data run event emitted readableStream invoked,

// once the RS finished the end event emitted and Writablestream invoked

var request = require('request');

var $ = request('http://www.google.com/');
// return to as a streams, gives back body of the resp
// html return from the http req those data has been fire pieces of the html sent to the function reg to the data event and ofcource in the console this how u whould interact with the readable stream 
$.on('data', function  (chunk) { 
	// the event that emitted from readable streams
	console.log('>>>Data>>:  \t'+chunk +'\n\n\n\n\n');
})

$.on('end', function  () {
	console.log('>>>Done>>');
})

Pipe BW streams

var request = require('request');
var s = request('http://www.google.com/');
s.pipe(process.stdout);


var request = require('request');
var fs = require('fs')
var zlib = require('zlib')
request('http://www.google.com/').pipe(zlib.createGzip()).pipe(fs.createWriteStream('pluralsight.html.gz'));
// writen as stream the passed into pipe

The "Process" object 
---------------------

process object node with the application  to both manage own process

. A colllection of Streams
	-- process.stdin
	-- process.stdout
	-- process.stderr
. Attribute of the current process
	-- process.env
	-- process.argv
	-- process.pid
	-- process.title
	-- process.uptime()
	-- process.memoryUsage()
	-- process.cwd()
	-- ..etc
. Process-related actions
	-- process.abort()
	-- process.chdir()
	-- process.kill()
	-- process.setgid()
	-- process.setuid()
	-- ...etc
. An instance of EE
	-- event: 'exit'
	-- event: 'uncaughtException'
	-- POSIX signal events ('SIGINT' etc)
process.stdin.resume();
// this stream cause passed, so u must called resume info 
process.stdin.setEncoding('utf8');

process.stdin.on('data', function  (chunk) {
	process.stdout.write('Data! -> '+chunk)
})

process.stdin.on('end', function  () {
	process.stderr.write('End! -> ')
})
process.on('SIGTERM', function  () {
	process.stderr.write('Why are trying to terminate me??')
})

console.log("Node is running as process a: "+process.pid);


interacting with the file system model we ad

Wrappers around POSIX functions (both async and sync versions)
	-- Function include:
	-- Ex fs.readdir(path, callback) and fs.readdirSync(path)
Stream oriented functions
	-- fs.createReadStream() - return an fs.ReadStream (a ReadableStream)
	-- fs.createWriteStream() - return an fs.WriteStream (a WritableSteam)
	// these are integrating to other streams as we allows a modules
Watch a file or directory for changes
	-- fs.watch() - return an fs. FSWatcher (an EE)
	-- change event: the type of change and the filename that changed
	-- error event emitted when and error occurs.

	var fs = require('fs');

if(fs.existsSync('temp')){
	console.log('Directory exists, removing....');
	if(fs.existsSync('temp/new.txt')){
		fs.unlinkSync('temp/new.txt');
	}
	fs.rmdirSync('temp')
}

fs.mkdirSync('temp');
if(fs.existsSync('temp')){
	process.chdir('temp');
	fs.writeFileSync('test.txt', 'This is some text for the file.');
	fs.renameSync('test.txt', 'new.txt');
	console.log('File has sizes' + fs.stateSync(new.txt).size + ' bytes')
	console.log('File contents' + fs.readFileSync(new.txt).toString())
}

Async

var fs = require('fs');

if(fs.existsSync('temp')){
	console.log('Directory exists, removing...');
	if(fs.existsSync('temp/new.txt')) fs.unlikeSync('temp/new.txt')
	fs.rmdirSync('temp')
}

fs.mkdir('temp', function(err){
	fs.exists('temp', function(exists){
		if(exists){
			process.chdir('temp');
			fs.writeFile('test.txt', 'This is some test for the file ', function  (err) {
					fs.rename('test.txt', 'new.txt', function  (err) {
						fs.stat('new.txt', function  (err, stats) {
							console.log('File has size: '+stats .size+' bytes')
							fs.readFile('new.txt', function(err, data){
								console.log('File contents :'+ data.toString());

							})
							// async/sync when we read the file from disk we take the value to return by readFileSync function and we call it toString on it, that going to be not string by default and we call it toString on the essence of the string obj to get the string value 
						})
					})
			})
		}
	})
})

What is a Buffer?

// u may rem u have to invoke 2 string method and val read a file from the file system, thats coz function val from the buffer object 
// js has difficulty dealing with binary data
// However,networking and the fs require it
// The Buffer class provides a raw memory allocation for dealing with binary data directly
// Buffers can be converted to/from strings by providing an encoding:
	-- ascii, utf8(default), utf16le, ucs2, base64, binary, hex
// Provides a handy way to convert strings to/from base64.

os module
provides info about the currently running system for examining the operating system while application is running,

os.tmpDir()
os.hostname()
os.type()
os.platform()
os.arch()
os.release()

os.uptime()
os.loadavg()
os.totalmem()
os.freemem()
os.cpus()
os.networkInterfaces()
os.EOL

Makink Web Requests in Node

var http = require('http');

var req = http.request(options, function(res){
	// process callback
});

-'options' can be one of the following:

A URL String
An object specifying values from host, port, method, path, headers, auth, etc

res-> instance of http clientReq (a WritableStream)
- The returned ClientRequest can be written/piped to for POST requests
// this is writableStrem these written pipe to http post, An addition written a value
- The ClientRes obj is provided via either callback (shown above) or as a 'response' event on the request object.
// this callback invoke just passed as a single parameter, which rep result of the http req this client res can be readablestream can read from part to a writablestream,
// callable function is not following written conventions, callback parameter not indicated 
// if don't pass a cb to the req function u still retrive the client res obj, it is also provided by res event emitted by client req return for the emitted function call, node provide simplifing req node http.get

var http = require('http');

var options = {
	host: 'www.pluralsight.com',
	port: 80,
	path: '/',
	method: 'GET'
};

console.log('Going to make request....');

// var req = http.request('http://www.google.com/', function  (response) {
// 	console.log(response.statusCode);
// 	response.pipe(process.stdout);
// });

// var req = http.request(options, function  (response) {
// 	console.log(response.statusCode);
// 	response.pipe(process.stdout);
// });

// // that is closing the writablestream giving when u make the req
// req.end();
// in get senario not going to uploading any data
http.get(options, function  (response) {
	console.log(response.statusCode);
	response.pipe(process.stdout);
});

// Build a Web Server in Node

var server = http.createServer(function(req, res){ // createServer parameter passed as a single parameter req received by the web server optionally there is no callback is provided req can also by rec listening for the server obj that is return 
// even have to server fuction have been return, server will begin until for listen function is called 
	// process request
})

// function can return several ways most common ip port comination
// when the req made to the http req and the callback is invoked its pass 2 parameter , 1 instence of server req readablestream 2 inst of server after upload req and pipe from res writableStream

- Each req is provided via either callback (shown above) of as a 'req' event on the server obj
- The ServerReq can be read from (or piped) for POST uploads
- the ServerRes can be piped to when returning stream-oriented data in a res
- SSL support is provided by a similar https.createServer()

var fs = require('fs');

var http = require('http');

http.createServer(function  (req, res) {
	res.writeHead(200, {'Content-Type': 'text/plain'});
	if(req.usl === '/file.txt')
		fs.createReadStream(__dirname + '/file.txt').pipe(res);
	else res.end('Hello world')
}).listen(process.env.PORT, process.env.IP);
console.log('Server running!', process.env.PORT, process.env.IP);


socket.io 
it used to maintain for active connection brow <--> servr
<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Test</title>
	<script>
		var socket;
		function onload () {
			socket = io.connect();
			socket.on('timer', function  (data) {
				document.getElementById('timer').innerHTML = data;
			});
			function submitData(){
				var data = document.getElementById('inputdata').value;
				socket.emit('submit', data);
			}
		}
	</script>
</head>
<body onload = "onload">
	<h1>Sample websocket page</h1>
	<p>Timer: <span id="timer"></span></p>
	<form action="#">
		<p>Data: <input type="text" id="inputdata" />
			<input type="button" onClick="submitData()">
		</p>
	</form>
</body>
</html>

var http = require('http');
var socketio = require('socket.io');
var fs = require('fs');

var handler = function  (req, res) {
	fs.readFile(__dirname+'/index.html', function  (err, data) {
		if (err) {
			res.writeHead(500);
			return res.end('Error loading index.html')
		} else {
			res.writeHead(200);
			res.end(data);
		}
	});
};

var app = http.createServer(handler);
var io = socketio.listen(app);

io.sockets.on('connection', function  (socket) {
	setInterval(function  () {
		var timestamp = Date.now();
		console.log('Emitted: '+timestamp);
		socket.emit('timer :'+timestamp)
	}, 2000);
	socket.on('submit', function  (data) {
		console.log('Submitted: '+data);
	});
});

app.listen(8080);
console.log('Server running!')
// later


Testing
// In this module basice unit test assert module 
the assert module it perform func and num of test assertion in ur code 
- Test (in)equality bw expected and actual values
- Test whether a block of code throws (or does not throw) an exception
- Test for the 'truthiness' of a value.
// coz node convention error param of callbacks
- Test whether the 'error' param was passed to a callback
// also test support for error on callback 
- Each assertion can contain a message to op on failure 

Test of equality
1. assert.equal(): shallow, coercive equality, as determined by == 
2. assert.strictEqual(): strict equality, as determined by ===
3. assert.deepEqual():
	- identical values are equal(===)
	- Values that are not objs (typeof 'object') are determined by ==
	- Date objs are equal if both refer to the same date/time
	- Other objs (including Arrays) are equal if they have the same num of owned props equivalent values every key and an identical 'prototype'

var assert = require('assert');
var maxTime = 1000;

// If input is even, double it
// If input is odd, error
// (call takes random amount of time < 1s)

var evenDoubler = function  (v, callback) {
	var waitTime = Math.floor(Math.random()*(maxTime+1))
	if (v%2) {
		setTimeout(function  () {
			callback(new Error("Odd input"));
		}, waitTime);
	}else {
		setTimeout(function  () {
			callback(null, v*2, waitTime);
		})
	}
}

// which as the same run which as number squaring event doubler, but instead of invoking the cb return a value it is passed an even number, and rather than passing odd number it throws an exception 
var evenDoublerSync = function(v) {
	if (v%2) {
		throw(new Error('Odd input'))
	} else {
		return(v*2)
	}
}

assert.equal(evenDoublerSync(2), 4);
assert.throws(function  () {
	evenDoublerSync(3);
},/Odd/); // exception throw regexp odd

evenDoubler(2, function(err, results) {
	assert.ifError(err);
	assert.equal(results, 5, 'evenDoubler failed on even number.')
});
evenDoubler(3, function  (err, results) {
	assert.notEqual(err, null);
});

// Mocha build in test capability provided by the assert model 
// there are many test framwork provided by node capability like mocha 
// it is also common to see u pair with should.js which provide a rich assertion syntax 
- Runs tests serially (both sync and async tests)
- Test cases are organized into test suites 
- Includes before(), after(), beforeEach() and afterEach() hooks.
- support for pending, exclusive and inclusive tests.
uppending test one has been step downs ur implementing, exclusive, inc test isolating test without having common help the test which u get uncomment later 
- Captures test duration, flagging tests that are slow
// during development cycle u can watch ur source directory re run the test each time of file changes, ex ide or txt edi
- Multiple 'interfaces' for writing tests(BSD, TDD, Exports, QUnit)
- Multiple 'reporters' for rendering test results

Asserting with should.js // sho extend 
- Extend Node's "assert" module with BDD style assertions,
- these make much easier to test and readable

 var user = {
 	name; 'tj',
 	pets: {'tobi', 'loki', 'jane', 'bandit'}
 };
 // should.js actually extend the prototype enhance a should function
 // extends Object with 'should' function syntactic sugar for readability enhanced assertions
 user.should.have.property('name', 'tj');
 user.should.have.property('pets').with.lengthOf(4);
 someAsyncTask(foo, function(err, results){
 	should.not.exist(err);
 	should.exist(result);

 	result.bar.should.equal(foo);
 });

should uppend the end of the obj(user) name coz obj und generate an error,
should function statically test in the error, sh not only available on top level variable on prop of obj as well let take a look test enhancment of mocha 

var should = require('should')
// should requiring bring in to but not requiring mocha , actuall install globally our system worked will learn from command line that y explicitly required here 
var maxTime = 1000;

// If input is even, double it
// If input is odd, error
// (call takes random amount of time < 1s)

var evenDoubler = function(v, callback) {
	var waitTime = Math.floor(Math.random()*(maxTime+1))
	if (v%2) {
		setTimeout(function  () {
			callback(new Error("Odd input"));
		}, waitTime);
	}else {
		setTimeout(function  () {
			callback(null, v*2, waitTime);
		})
	}
}

// which as the same run which as number squaring event doubler, but instead of invoking the cb return a value it is passed an even number, and rather than passing odd number it throws an exception 
var evenDoublerSync = function(v) {
	if (v%2) {
		throw(new Error('Odd input'))
	} else {
		return(v*2)
	}
}


describe('MathFun', function () {
	// dec is making test sweets
	describe('when used synchronously', function  () {
		it('should double even number correctly', function  () {
			// it should double even numbers correctly
			evenDoublerSync(2).should.equal(4);
		})
		it.skip('should throw on odd numbers', function  (done) {
			(function  () {
				evenDoublerSync(3)
			}).should.throw(/Odd/);
			done();
			// its particul done async provide to, becomes even more important
		})
	});
	describe('when used async', function  () {
		it('should double even number correctly', function  (done) {
			evenDoubler(2, function(err, results) {
				should.not.exist(err);
				results.should.equal(5);
				done(); /// tell to mocha these test is done
			});
		})
		it('should return error on odd number', function  (done) {
			evenDoubler(3, function  (err, results) {
				should.exist(err);
				should.not.exist(results);
				done();
			});
		})
	})
})
// mocha -R spec Example.js
// -R reporter for spec


Scaling node application
- Creating child processes in node
- Scaling ur node app with the 'cluster' module, across processors

Creating Child Processes

// One common criticesum node process its a don't handle the cpu intensive task well, this is coz to cpu timer anyone task node app will block the event loop provide other work for being done, one stargie dealing with issue is the use of child processors, a cpu intensive task can be confirm to child process while the main node app cont to process events
// node as 4 ways to launch child process, and all a part of child process module 
	1. spawn(command, [args], [options])
		- Launches a new process with 'command' and 'args'
		- returns a ChildProcess object that...
			- is an EE and emits 'exit' and 'close' events // which can be listen for parent node app
			- has streams for stdin, stdout and stderr that can be piped to/from
	2. exec(command, [options], callback)
		- Runs 'command' string in a shell// u can pipe bw unix command without single invokcation exec 
		- Callback is invoked on process completion with error, stdout, stderr
	3. execFile(file, [args], [options], callback)
		- Similar to 'exec', except 'file' is executed directly, rather than in a subshell

// one child node process is particularly optimized new child node processors this done with the fork function, this is specialize with the spawn function officially creating node process spawn it return an instance of the child processor, in this case it has the same function in additional an event to facilitate msg passing in the parent and child processes
	4. fork(modulePath, [args], [options])
		- A special version of 'spawn' especially for creating Node processes
		- Adds a 'send' function and 'message' event to ChildProcess

parent.js
var cp = require('child_process');

var n = cp.fork(__dirname + '/child.js');

n.on('message', function(m){
	console.log('PARENT got message: ', m);
});
n.send({ hello: 'world' });

// sending msg to the return child process object attend newly to process 
// In the sperate child.js listen to the log on console

process.on('message', function(){
	console.lo('CHILD got message:', m);
});

process.send({ foo: 'bar' })
// it too attend send msg to back to parent 

var exec = require('child_process').exec;

// when uptime unix function it callback will allow u to the, exact arbitory command on ur system
var child = exec('uptime | cut -d "," -f 1', function  (err, stdin, stderr) {
	if(err) console.log('Error: '+stderr);
	else console.log('Output is: '+stdout);
});

console.log('PID is '+child.pid);

var spawn = require('child_process').spawn,
	ps = spawn('ps', ['ax']),
	grep = spawn('grep', ['node']);
// spwn fun is give u more control of stdin/out/err process
// we gave access to stdout error once the process was complete 
// in this case actually feed data stdin, and get data from stdout while the process is running , std is streams while among to other 


ps.stdout.pipe(grep.stdin);
grep.stdout.pipe(process.stdout);

ps.stderr.on('data', function  (data) {
	console.log('ps stderr: ' + data);
});

grep.stderr.on('data', function  (data) {
	console.log('grep stderr: ' + data);
});

// Fork
process.on('message', function  (m) {
	if(m.cmd === 'double'){
		console.log('hs: I was asked to double ', m.number);
		evenDouble(m.number, function  (err, result) {
			// wrap evenDouble function here, child invokes the msg 
			// in the child proce reg function of the process object, msg invoking the function
			// function going to the get the command obj sending cmd variable, if cmd variable is set to double 
			// going to the lot of the console if us ask to the double even process and we get to answer back we getting to the process again
			// to send a msg back to the parent send the json objec were contain the result 
			process.send({ answer: result })
		});
	} else if(m.cmd === 'done') process.exit();
})

var fork = require('child_process').fork
// build on spwn , spwn special design on child_process node app
var child = fork(__dirname + '/Example1.js');

child.on('message', function  (m) {
	console.log('The answer is: ', m.answer);
	child.send({ cmd: 'done' })
})
child.send({ cmd: 'double', number: 20 })

// hs: I was asked to double  20
// when rec msg comm double 
// The answer is:  40
// parent prcess he rec child back the answer
// fork function message bw child prcess 


// Scaling with Node's 'cluster' module

// module leveraging child_process.fork();
// Introduces a "Worker" class as well as master function and events

// typical scenario node js script working as a master
{
	master,  //the cluster module provides variable, which will tell u the node running in the masters 
	// To create worker node actually node js worker processors, cluster provides a fork function, by default fork run the same njs script worker as the masters
	//fork()
	// isMater() variable as large if statement, to exe fork func to mark fork event in the master
	// event: fork
	// event: online
	// event: lisening
}

// Once the master is spawned master is also indicating the workers
// addtion worker can be created subsequence work function 
// cluster also provide subsequence wroker indicates, whether code exe in worker node 
// common cluster scenair a spawning multiple worker node to create scalable scernario

// if the worker exe a listen function, listening event emitting on the master 
// pass a handle back to the worker

{
	.isWorker
	server.listen(ip1, 80)
}
{
	.isWorker
	server.listen(ip1, 80)
}
// but master listen to the same handle worker, listen on same ip combination itis upto the os incoming req bw worker processes do not proxy to the masters req can send directly send to the worker processes 


var cluster = require('cluster');
var http = require('http');
var numWorker = 2;

if(cluster.isMaster){
	// Master prcess will do
	for (var i = 0; i < numWorker; i++) {
		console.log('master: about to fork a worker');
		cluster.fork();
	};
	cluster.on('fork', function  (worker) {
		console.log('master: fork event (worker '+worker.id+')');
	})
	cluster.on('online', function  (worker) {
		console.log('master: online event (worker '+worker.id+')');
	})
	cluster.on('listening', function  (worker, address) {
		console.log('master: listening event (worker '+worker.id+', pid'+worker.process.id +', '+address.address + ':' + address.port+')');
	})
	cluster.on('exit', function  (worker, code, signal) {
		console.log('master: exit event (worker '+worker.id+')');
	})

} else {
	// child process will do
	console.log('worker: worker # '+cluster.worker.id+' ready!');
	var count = 0;

	// worker can share any tcp connection 
	// In this case its a http server

	http.createServer(function  (req, res) {
		res.writeHead(200);
		// console.dir(req);
		count++;
		console.log('Worker #'+cluster.worker.id+" is incrementing count to " +count);
		res.end("hello world from worker #"+cluster.worker.id+" {pid "+ cluster.worker.process.pid +"} with count = "+ count + "\n");
		// once the particular server has req destroy the req
		if (count === 3) {cluster.worker.destroy()};
	}).listen(process.env.PORT, process.env.IP)
	// }).listen(1111, "localhost")
}